{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","mount_file_id":"1kqZyuJvyD-62CZKMoalVNpdJ0Fi0qxNk","authorship_tag":"ABX9TyP2utid9rrHO70ub3i7OjQR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IlWsxLTNh1Bl","executionInfo":{"status":"ok","timestamp":1714661786966,"user_tz":-120,"elapsed":5,"user":{"displayName":"Mohammed El-dor","userId":"10177968864037735714"}},"outputId":"d4d5f7cf-b2ac-4025-caa9-2854d1874339"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Thesis_Organized/Detectron2\n"]}],"source":["cd //content/drive/MyDrive/Thesis_Organized/Detectron2"]},{"cell_type":"code","source":["!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"],"metadata":{"id":"falQjjqUiGA2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train_test_hpc.py --momentum 0.95 --learning_rate 0.005 --lr_decay True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"phjrjHY3iH8M","executionInfo":{"status":"ok","timestamp":1714662207585,"user_tz":-120,"elapsed":394535,"user":{"displayName":"Mohammed El-dor","userId":"10177968864037735714"}},"outputId":"a09a046b-555d-4bd9-9f42-860f571451d5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m[05/02 14:56:58 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (6): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (7): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (8): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (9): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (10): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (11): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (12): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (13): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (14): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (15): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (16): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (17): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (18): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (19): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (20): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (21): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (22): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/02 14:56:58 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[05/02 14:56:58 d2.data.datasets.coco]: \u001b[0mLoaded 791 images in COCO format from /content/drive/MyDrive/Thesis_Organized/Data/COCO_Format/coco_train_data.json\n","\u001b[32m[05/02 14:56:59 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 791 images left.\n","\u001b[32m[05/02 14:56:59 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n","\u001b[36m|  category  | #instances   |\n","|:----------:|:-------------|\n","|   Track    | 2402         |\n","|            |              |\u001b[0m\n","\u001b[32m[05/02 14:56:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[05/02 14:56:59 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[05/02 14:56:59 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","\u001b[32m[05/02 14:56:59 d2.data.common]: \u001b[0mSerializing 791 elements to byte tensors and concatenating them all ...\n","\u001b[32m[05/02 14:56:59 d2.data.common]: \u001b[0mSerialized dataset takes 4.34 MiB\n","\u001b[32m[05/02 14:56:59 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=8\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/02 14:56:59 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","\u001b[32m[05/02 14:56:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')]\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/02 14:56:59 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[05/02 14:56:59 d2.data.datasets.coco]: \u001b[0mLoaded 97 images in COCO format from /content/drive/MyDrive/Thesis_Organized/Data/COCO_Format/coco_val_data.json\n","\u001b[32m[05/02 14:56:59 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n","\u001b[36m|  category  | #instances   |\n","|:----------:|:-------------|\n","|   Track    | 309          |\n","|            |              |\u001b[0m\n","\u001b[32m[05/02 14:56:59 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","\u001b[32m[05/02 14:56:59 d2.data.common]: \u001b[0mSerializing 97 elements to byte tensors and concatenating them all ...\n","\u001b[32m[05/02 14:56:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.55 MiB\n","\u001b[32m[05/02 14:56:59 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl ...\n","Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n","Some model parameters or buffers are not found in the checkpoint:\n","\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n","\u001b[32m[05/02 14:56:59 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[32m[05/02 14:58:08 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 19  total_loss: 1.102  loss_cls: 0.2614  loss_box_reg: 0.1604  loss_mask: 0.609  loss_rpn_cls: 0.07927  loss_rpn_loc: 0.06864  validation_loss: 1.111    time: 2.8576  last_time: 2.6000  data_time: 0.4214  last_data_time: 0.0744   lr: 0.00095405  max_mem: 19167M\n","2024-05-02 14:58:08.605293: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-02 14:58:08.605341: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-02 14:58:08.607177: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-02 14:58:09.694714: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/02 14:59:06 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[05/02 14:59:06 d2.data.datasets.coco]: \u001b[0mLoaded 97 images in COCO format from /content/drive/MyDrive/Thesis_Organized/Data/COCO_Format/coco_val_data.json\n","\u001b[32m[05/02 14:59:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[05/02 14:59:06 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","\u001b[32m[05/02 14:59:06 d2.data.common]: \u001b[0mSerializing 97 elements to byte tensors and concatenating them all ...\n","\u001b[32m[05/02 14:59:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.55 MiB\n","\u001b[32m[05/02 14:59:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 97 batches\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[32m[05/02 14:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/97. Dataloading: 0.0013 s/iter. Inference: 0.0775 s/iter. Eval: 0.0120 s/iter. Total: 0.0908 s/iter. ETA=0:00:07\n","\u001b[32m[05/02 14:59:12 d2.evaluation.evaluator]: \u001b[0mInference done 67/97. Dataloading: 0.0015 s/iter. Inference: 0.0759 s/iter. Eval: 0.0121 s/iter. Total: 0.0896 s/iter. ETA=0:00:02\n","\u001b[32m[05/02 14:59:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.276635 (0.089963 s / iter per device, on 1 devices)\n","\u001b[32m[05/02 14:59:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.075913 s / iter per device, on 1 devices)\n","\u001b[32m[05/02 14:59:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[05/02 14:59:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","\u001b[32m[05/02 14:59:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[05/02 14:59:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n","\u001b[32m[05/02 14:59:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[05/02 14:59:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.185\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.491\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.079\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.243\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.112\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.329\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.188\n","\u001b[32m[05/02 14:59:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n","|:------:|:------:|:------:|:-----:|:------:|:-----:|\n","| 18.483 | 49.108 | 7.919  | 8.289 | 24.272 | 0.346 |\n","Loading and preparing results...\n","DONE (t=0.02s)\n","creating index...\n","index created!\n","\u001b[32m[05/02 14:59:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n","\u001b[32m[05/02 14:59:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n","\u001b[32m[05/02 14:59:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[05/02 14:59:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.018\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.026\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.028\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n","\u001b[32m[05/02 14:59:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n","|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n","|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n","| 0.128 | 1.067  | 0.000  | 0.000 | 0.163 | 0.594 |\n","\u001b[32m[05/02 14:59:15 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n","\u001b[32m[05/02 14:59:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[05/02 14:59:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[05/02 14:59:15 d2.evaluation.testing]: \u001b[0mcopypaste: 18.4827,49.1084,7.9194,8.2888,24.2717,0.3461\n","\u001b[32m[05/02 14:59:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n","\u001b[32m[05/02 14:59:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[05/02 14:59:15 d2.evaluation.testing]: \u001b[0mcopypaste: 0.1282,1.0669,0.0000,0.0000,0.1632,0.5941\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[32m[05/02 14:59:24 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 39  total_loss: 0.8916  loss_cls: 0.1722  loss_box_reg: 0.2552  loss_mask: 0.375  loss_rpn_cls: 0.02494  loss_rpn_loc: 0.03943  validation_loss: 0.8204    time: 2.8269  last_time: 2.3785  data_time: 0.3447  last_data_time: 0.0706   lr: 0.0019531  max_mem: 19286M\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[32m[05/02 15:00:29 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 59  total_loss: 0.7278  loss_cls: 0.1272  loss_box_reg: 0.2685  loss_mask: 0.2763  loss_rpn_cls: 0.01315  loss_rpn_loc: 0.03478  validation_loss: 0.6414    time: 2.8151  last_time: 2.4400  data_time: 0.3321  last_data_time: 0.0733   lr: 0.002952  max_mem: 19512M\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/02 15:01:29 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[05/02 15:01:29 d2.data.datasets.coco]: \u001b[0mLoaded 97 images in COCO format from /content/drive/MyDrive/Thesis_Organized/Data/COCO_Format/coco_val_data.json\n","\u001b[32m[05/02 15:01:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[05/02 15:01:29 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","\u001b[32m[05/02 15:01:29 d2.data.common]: \u001b[0mSerializing 97 elements to byte tensors and concatenating them all ...\n","\u001b[32m[05/02 15:01:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.55 MiB\n","\u001b[32m[05/02 15:01:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 97 batches\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[32m[05/02 15:01:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/97. Dataloading: 0.0012 s/iter. Inference: 0.0821 s/iter. Eval: 0.0062 s/iter. Total: 0.0896 s/iter. ETA=0:00:07\n","\u001b[32m[05/02 15:01:35 d2.evaluation.evaluator]: \u001b[0mInference done 69/97. Dataloading: 0.0015 s/iter. Inference: 0.0771 s/iter. Eval: 0.0088 s/iter. Total: 0.0874 s/iter. ETA=0:00:02\n","\u001b[32m[05/02 15:01:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.965383 (0.086580 s / iter per device, on 1 devices)\n","\u001b[32m[05/02 15:01:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.076812 s / iter per device, on 1 devices)\n","\u001b[32m[05/02 15:01:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[05/02 15:01:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","\u001b[32m[05/02 15:01:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[05/02 15:01:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n","\u001b[32m[05/02 15:01:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[05/02 15:01:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.810\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.407\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.112\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.515\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.531\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.237\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.539\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.541\n","\u001b[32m[05/02 15:01:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n","|:------:|:------:|:------:|:------:|:------:|:------:|\n","| 41.915 | 81.020 | 40.687 | 17.625 | 47.404 | 11.182 |\n","Loading and preparing results...\n","DONE (t=0.01s)\n","creating index...\n","index created!\n","\u001b[32m[05/02 15:01:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n","\u001b[32m[05/02 15:01:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n","\u001b[32m[05/02 15:01:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[05/02 15:01:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.812\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.159\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.147\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.431\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.237\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n","\u001b[32m[05/02 15:01:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 34.648 | 81.183 | 15.890 | 8.476 | 35.726 | 37.946 |\n","\u001b[32m[05/02 15:01:37 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n","\u001b[32m[05/02 15:01:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[05/02 15:01:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[05/02 15:01:37 d2.evaluation.testing]: \u001b[0mcopypaste: 41.9146,81.0197,40.6874,17.6249,47.4040,11.1821\n","\u001b[32m[05/02 15:01:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n","\u001b[32m[05/02 15:01:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[05/02 15:01:37 d2.evaluation.testing]: \u001b[0mcopypaste: 34.6476,81.1831,15.8898,8.4763,35.7263,37.9459\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[32m[05/02 15:01:46 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 79  total_loss: 0.5843  loss_cls: 0.1181  loss_box_reg: 0.1938  loss_mask: 0.2057  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.03706  validation_loss: 0.54    time: 2.8578  last_time: 2.3015  data_time: 0.4859  last_data_time: 0.0810   lr: 0.0039511  max_mem: 19576M\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[32m[05/02 15:02:59 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 99  total_loss: 0.4934  loss_cls: 0.09974  loss_box_reg: 0.1646  loss_mask: 0.1757  loss_rpn_cls: 0.009856  loss_rpn_loc: 0.03232  validation_loss: 0.5077    time: 2.8999  last_time: 2.5800  data_time: 0.5694  last_data_time: 0.0728   lr: 0.0049501  max_mem: 19576M\n","\u001b[32m[05/02 15:02:59 d2.engine.hooks]: \u001b[0mOverall training speed: 98 iterations in 0:04:44 (2.8999 s / it)\n","\u001b[32m[05/02 15:02:59 d2.engine.hooks]: \u001b[0mTotal training time: 0:05:51 (0:01:07 on hooks)\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/02 15:02:59 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[05/02 15:02:59 d2.data.datasets.coco]: \u001b[0mLoaded 97 images in COCO format from /content/drive/MyDrive/Thesis_Organized/Data/COCO_Format/coco_val_data.json\n","\u001b[32m[05/02 15:02:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[05/02 15:02:59 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","\u001b[32m[05/02 15:02:59 d2.data.common]: \u001b[0mSerializing 97 elements to byte tensors and concatenating them all ...\n","\u001b[32m[05/02 15:02:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.55 MiB\n","\u001b[32m[05/02 15:02:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 97 batches\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[32m[05/02 15:03:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/97. Dataloading: 0.0014 s/iter. Inference: 0.0794 s/iter. Eval: 0.0041 s/iter. Total: 0.0849 s/iter. ETA=0:00:07\n","\u001b[32m[05/02 15:03:05 d2.evaluation.evaluator]: \u001b[0mInference done 67/97. Dataloading: 0.0017 s/iter. Inference: 0.0796 s/iter. Eval: 0.0080 s/iter. Total: 0.0893 s/iter. ETA=0:00:02\n","\u001b[32m[05/02 15:03:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.173838 (0.088846 s / iter per device, on 1 devices)\n","\u001b[32m[05/02 15:03:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.079534 s / iter per device, on 1 devices)\n","\u001b[32m[05/02 15:03:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[05/02 15:03:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","\u001b[32m[05/02 15:03:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[05/02 15:03:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n","\u001b[32m[05/02 15:03:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[05/02 15:03:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.851\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.449\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.410\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.554\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.560\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.550\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.559\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.582\n","\u001b[32m[05/02 15:03:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n","|:------:|:------:|:------:|:------:|:------:|:------:|\n","| 47.108 | 85.146 | 44.879 | 40.985 | 52.874 | 17.406 |\n","Loading and preparing results...\n","DONE (t=0.01s)\n","creating index...\n","index created!\n","\u001b[32m[05/02 15:03:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n","\u001b[32m[05/02 15:03:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n","\u001b[32m[05/02 15:03:08 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[05/02 15:03:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.416\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.845\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.362\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.324\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.419\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.449\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.482\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.550\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.485\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\n","\u001b[32m[05/02 15:03:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n","|:------:|:------:|:------:|:------:|:------:|:------:|\n","| 41.595 | 84.478 | 36.201 | 32.414 | 41.880 | 44.892 |\n","\u001b[32m[05/02 15:03:08 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n","\u001b[32m[05/02 15:03:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[05/02 15:03:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[05/02 15:03:08 d2.evaluation.testing]: \u001b[0mcopypaste: 47.1082,85.1459,44.8785,40.9852,52.8740,17.4064\n","\u001b[32m[05/02 15:03:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n","\u001b[32m[05/02 15:03:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[05/02 15:03:08 d2.evaluation.testing]: \u001b[0mcopypaste: 41.5948,84.4778,36.2006,32.4144,41.8800,44.8922\n","\u001b[32m[05/02 15:03:10 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./train_results/X101_l1smooth_0.95_0.005_True/model_final.pth ...\n","100% 8/8 [00:01<00:00,  4.53it/s]\n","100% 97/97 [00:12<00:00,  7.96it/s]\n","100% 97/97 [00:00<00:00, 71027.84it/s]\n","100% 97/97 [00:00<00:00, 115319.58it/s]\n","100% 97/97 [00:00<00:00, 78648.27it/s]\n","100% 97/97 [00:00<00:00, 81369.50it/s]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"I9EUR1iYjCvi"},"execution_count":null,"outputs":[]}]}