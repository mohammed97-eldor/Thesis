{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1710606741750,"user":{"displayName":"Mohammed El-dor","userId":"10177968864037735714"},"user_tz":-60},"id":"e8titc9sGKEt","outputId":"a97d56d4-d4e5-4e3b-d3f9-78e8ed41fb78"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Thesis_Organized\n"]}],"source":["cd /content/drive/MyDrive/Thesis_Organized"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tgPa9v-OHGkL"},"outputs":[],"source":["!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":275,"status":"ok","timestamp":1710607041788,"user":{"displayName":"Mohammed El-dor","userId":"10177968864037735714"},"user_tz":-60},"id":"UesCMdsjG27g","outputId":"386021d5-15fa-43ed-f6aa-a096269cf42b"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Thesis_Organized'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","from tqdm import tqdm\n","main_dir = os.getcwd()\n","main_dir"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2345,"status":"ok","timestamp":1710607045496,"user":{"displayName":"Mohammed El-dor","userId":"10177968864037735714"},"user_tz":-60},"id":"A47hT5s5HCzG","outputId":"8d30ffa5-c24e-4b8f-efca-81d0334b4d3c"},"outputs":[{"name":"stdout","output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n","torch:  2.2 ; cuda:  cu121\n","detectron2: 0.6\n"]}],"source":["# Setups\n","import torch, detectron2\n","!nvcc --version\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","print(\"detectron2:\", detectron2.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O7ZnV4ZhIAdE"},"outputs":[],"source":["import detectron2\n","# from detectron2.utils.logger import setup_logger\n","# setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import cv2\n","import random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":265,"status":"ok","timestamp":1710608317550,"user":{"displayName":"Mohammed El-dor","userId":"10177968864037735714"},"user_tz":-60},"id":"ecEqiTYvIYWd","outputId":"478700a0-8240-4a96-9222-4cd219657ea9"},"outputs":[{"data":{"text/plain":["(0.9, 0.00016)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# importing\n","from Detectron2.detectron_conf import *\n","Detectron2_cfg[\"Momentum\"], Detectron2_cfg[\"base_lr\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XT4Pp8m9IDC_"},"outputs":[],"source":["from detectron2.data.datasets import register_coco_instances\n","register_coco_instances(\"my_dataset_train\", {}, Data_cfg[\"Coco_labels_train_dir\"], os.path.join(Data_cfg[\"cropped_Images_dir\"], \"Train\"))\n","register_coco_instances(\"my_dataset_test\", {}, Data_cfg[\"Coco_labels_test_dir\"], os.path.join(Data_cfg[\"cropped_Images_dir\"], \"Test\"))\n","register_coco_instances(\"my_dataset_val\", {}, Data_cfg[\"Coco_labels_val_dir\"], os.path.join(Data_cfg[\"cropped_Images_dir\"], \"Val\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SR4kNY0DIQh2"},"outputs":[],"source":["from detectron2.engine.hooks import HookBase\n","from detectron2.evaluation import inference_context\n","from detectron2.utils.logger import log_every_n_seconds\n","from detectron2.data import DatasetMapper, build_detection_test_loader\n","import detectron2.utils.comm as comm\n","import torch\n","import time\n","import datetime\n","import logging\n","import numpy as np  # Ensure numpy is imported for mean calculation\n","\n","class LossEvalHook(HookBase):\n","    \"\"\"\n","    A custom hook for periodically evaluating the loss on a validation dataset during training.\n","\n","    This hook leverages Detectron2's HookBase to integrate loss evaluation directly into the training loop.\n","    It computes the loss for each batch in the provided data loader and calculates the mean loss over the entire dataset.\n","    This mean loss is then logged and stored for monitoring the model's performance on unseen data during training.\n","\n","    Attributes:\n","        _model (torch.nn.Module): The model being trained and evaluated.\n","        _period (int): The evaluation period, i.e., how often (in terms of training iterations) to evaluate.\n","        _data_loader (iterable): The data loader for the validation dataset.\n","    \"\"\"\n","\n","    def __init__(self, eval_period, model, data_loader):\n","        \"\"\"\n","        Initializes the LossEvalHook.\n","\n","        Args:\n","            eval_period (int): The number of training iterations between each evaluation.\n","            model (torch.nn.Module): The model that will be evaluated.\n","            data_loader (iterable): The DataLoader providing the validation dataset.\n","        \"\"\"\n","        self._model = model\n","        self._period = eval_period\n","        self._data_loader = data_loader\n","\n","    def _do_loss_eval(self):\n","        \"\"\"\n","        Perform the loss evaluation on the validation dataset.\n","\n","        Iterates over the validation dataset, computes the loss for each batch, and calculates the mean loss.\n","        This function also handles logging progress and synchronization in distributed training setups.\n","\n","        Returns:\n","            List of loss values for each batch in the validation dataset.\n","        \"\"\"\n","        total = len(self._data_loader)  # Total number of batches\n","        num_warmup = min(5, total - 1)  # Number of batches to skip for warm-up\n","\n","        start_time = time.perf_counter()\n","        total_compute_time = 0\n","        losses = []  # Store losses for each batch\n","        for idx, inputs in enumerate(self._data_loader):\n","            # Reset timing and loss calculation after warm-up period\n","            if idx == num_warmup:\n","                start_time = time.perf_counter()\n","                total_compute_time = 0\n","            start_compute_time = time.perf_counter()\n","            if torch.cuda.is_available():\n","                torch.cuda.synchronize()  # Ensure synchronization in CUDA operations\n","            total_compute_time += time.perf_counter() - start_compute_time\n","            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n","            seconds_per_img = total_compute_time / iters_after_start\n","            # Log progress and ETA after warm-up period\n","            if idx >= num_warmup * 2 or seconds_per_img > 5:\n","                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n","                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n","                log_every_n_seconds(\n","                    logging.INFO,\n","                    f\"Loss on Validation  done {idx + 1}/{total}. {seconds_per_img:.4f} s / img. ETA={eta}\",\n","                    n=5,\n","                )\n","            loss_batch = self._get_loss(inputs)  # Compute loss for the current batch\n","            losses.append(loss_batch)\n","        mean_loss = np.mean(losses)  # Calculate mean loss\n","        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n","        comm.synchronize()  # Synchronize across all processes\n","\n","        return losses\n","\n","    def _get_loss(self, data):\n","        \"\"\"\n","        Calculate and return the loss for a batch of data.\n","\n","        This method forwards the data through the model and aggregates the loss values.\n","\n","        Args:\n","            data (dict): A batch of data to be processed by the model.\n","\n","        Returns:\n","            float: The total loss for the batch.\n","        \"\"\"\n","        metrics_dict = self._model(data)\n","        # Ensure all metrics are scalars and detach any tensors from the graph\n","        metrics_dict = {\n","            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n","            for k, v in metrics_dict.items()\n","        }\n","        total_losses_reduced = sum(loss for loss in metrics_dict.values())  # Sum up the losses\n","        return total_losses_reduced\n","\n","    def after_step(self):\n","        next_iter = self.trainer.iter + 1\n","        is_final = next_iter == self.trainer.max_iter\n","        if is_final or (self._period > 0 and next_iter % self._period == 0):\n","            self._do_loss_eval()\n","        self.trainer.storage.put_scalars(timetest=12)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOJnGF0rQs1_"},"outputs":[],"source":["from detectron2.data import DatasetMapper, build_detection_test_loader, build_detection_train_loader\n","from detectron2.engine import DefaultTrainer\n","from detectron2.data.transforms import RandomApply, RandomBrightness, RandomRotation, RandomFlip, RandomCrop, RandomContrast\n","from detectron2.config import CfgNode\n","from detectron2.solver.build import get_default_optimizer_params, maybe_add_gradient_clipping\n","import torch\n","\n","class CustomTrainer(DefaultTrainer):\n","    \"\"\"\n","    This class extends Detectron2's DefaultTrainer to include custom behavior for the training process.\n","    It allows for the addition of a loss evaluation hook to periodically assess the model's performance\n","    on a validation or test set during training. Moreover, it customizes the data loading with specific\n","    data augmentations and utilizes a custom optimizer configuration.\n","    \"\"\"\n","\n","    def build_hooks(self):\n","        \"\"\"\n","        Overrides the DefaultTrainer's build_hooks method to insert a custom hook for evaluating\n","        the loss on a validation or test set during the training process. This enables monitoring\n","        the model's performance beyond the training set, providing insights into its generalization capabilities.\n","\n","        Returns:\n","            List[HookBase]: A list of hooks including the custom LossEvalHook for periodic loss evaluation.\n","        \"\"\"\n","        # First, call the parent class's build_hooks method to get the default set of hooks.\n","        hooks = super().build_hooks()\n","\n","        # Insert the custom LossEvalHook before the last hook.\n","        # This ensures that the loss evaluation is performed at the specified intervals.\n","        hooks.insert(-1, LossEvalHook(\n","            eval_period=20,  # Specifies the interval (in terms of training iterations) for performing loss evaluation.\n","            model=self.model,  # Passes the current model for evaluation.\n","            data_loader=build_detection_test_loader(\n","                self.cfg,\n","                self.cfg.DATASETS.TEST[0],  # Specifies the dataset used for evaluation.\n","                DatasetMapper(self.cfg, is_train=True)  # Uses the DatasetMapper with the current configuration.\n","            )\n","        ))\n","\n","        return hooks\n","\n","    @classmethod\n","    def build_train_loader(cls, cfg):\n","        \"\"\"\n","        Customizes the training DataLoader by specifying data augmentations that are applied\n","        to the training dataset. This method enhances the model's ability to generalize by introducing\n","        variability into the training data.\n","\n","        Args:\n","            cfg (CfgNode): Configuration node containing settings for data loading and augmentations.\n","\n","        Returns:\n","            DataLoader: A DataLoader for training, configured with custom data augmentations.\n","        \"\"\"\n","        # Defines a mapper that applies a series of data augmentations to each training example.\n","        mapper = DatasetMapper(cfg, is_train=True, augmentations=[\n","            # Randomly applies brightness adjustment with the specified probability.\n","            RandomApply(RandomBrightness(*Augmentation_cfg[\"RandomBrightness\"][:-1]), Augmentation_cfg[\"RandomBrightness\"][-1]),\n","            # Randomly applies rotation with the specified probability.\n","            RandomApply(RandomRotation(angle=Augmentation_cfg[\"RandomRotation\"][:-1]), Augmentation_cfg[\"RandomRotation\"][-1]),\n","            # Randomly applies horizontal flip with the specified probability.\n","            RandomApply(RandomFlip(), Augmentation_cfg[\"RandomFlip\"][0]),\n","            # Randomly applies cropping with the specified probability.\n","            RandomApply(RandomCrop(\"relative\", Augmentation_cfg[\"RandomCrop\"][:-1]), Augmentation_cfg[\"RandomCrop\"][-1]),\n","            # Randomly applies contrast adjustment with the specified probability.\n","            RandomApply(RandomContrast(*Augmentation_cfg[\"RandomContrast\"][:-1]), Augmentation_cfg[\"RandomContrast\"][-1])\n","        ])\n","\n","        # Builds and returns a DataLoader using the defined mapper for data augmentation.\n","        return build_detection_train_loader(cfg, mapper=mapper)\n","\n","    @classmethod\n","    def build_optimizer(cls, cfg: CfgNode, model: torch.nn.Module) -> torch.optim.Optimizer:\n","        \"\"\"\n","        Configures and returns a custom optimizer for the model, using the AdamW algorithm.\n","        This method allows for custom settings for the optimizer, including learning rates, weight decay, and possibly\n","        gradient clipping, based on the provided configuration.\n","\n","        Args:\n","            cfg (CfgNode): Configuration node containing optimizer settings.\n","            model (torch.nn.Module): The model for which the optimizer is being configured.\n","\n","        Returns:\n","            torch.optim.Optimizer: An instance of the AdamW optimizer with configured parameters.\n","        \"\"\"\n","        # Retrieves default parameters for optimizer setup, including learning rate and weight decay adjustments.\n","        params = get_default_optimizer_params(\n","            model,\n","            base_lr=cfg.SOLVER.BASE_LR,\n","            weight_decay_norm=cfg.SOLVER.WEIGHT_DECAY_NORM,\n","            bias_lr_factor=cfg.SOLVER.BIAS_LR_FACTOR,\n","            weight_decay=cfg.SOLVER.WEIGHT_DECAY,\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0FGk14CySBZv"},"outputs":[],"source":["from detectron2.engine import DefaultTrainer\n","cfg = get_cfg()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1710611586977,"user":{"displayName":"Mohammed El-dor","userId":"10177968864037735714"},"user_tz":-60},"id":"SQAf7cPfSM6T","outputId":"3d9161e4-299e-47d7-ae64-33f6c9a1e54b"},"outputs":[{"data":{"text/plain":["CfgNode({'VERSION': 2, 'MODEL': CfgNode({'LOAD_PROPOSALS': False, 'MASK_ON': False, 'KEYPOINT_ON': False, 'DEVICE': 'cuda', 'META_ARCHITECTURE': 'GeneralizedRCNN', 'WEIGHTS': '', 'PIXEL_MEAN': [103.53, 116.28, 123.675], 'PIXEL_STD': [1.0, 1.0, 1.0], 'BACKBONE': CfgNode({'NAME': 'build_resnet_backbone', 'FREEZE_AT': 2}), 'FPN': CfgNode({'IN_FEATURES': [], 'OUT_CHANNELS': 256, 'NORM': '', 'FUSE_TYPE': 'sum'}), 'PROPOSAL_GENERATOR': CfgNode({'NAME': 'RPN', 'MIN_SIZE': 0}), 'ANCHOR_GENERATOR': CfgNode({'NAME': 'DefaultAnchorGenerator', 'SIZES': [[32, 64, 128, 256, 512]], 'ASPECT_RATIOS': [[0.5, 1.0, 2.0]], 'ANGLES': [[-90, 0, 90]], 'OFFSET': 0.0}), 'RPN': CfgNode({'HEAD_NAME': 'StandardRPNHead', 'IN_FEATURES': ['res4'], 'BOUNDARY_THRESH': -1, 'IOU_THRESHOLDS': [0.3, 0.7], 'IOU_LABELS': [0, -1, 1], 'BATCH_SIZE_PER_IMAGE': 256, 'POSITIVE_FRACTION': 0.5, 'BBOX_REG_LOSS_TYPE': 'smooth_l1', 'BBOX_REG_LOSS_WEIGHT': 1.0, 'BBOX_REG_WEIGHTS': (1.0, 1.0, 1.0, 1.0), 'SMOOTH_L1_BETA': 0.0, 'LOSS_WEIGHT': 1.0, 'PRE_NMS_TOPK_TRAIN': 12000, 'PRE_NMS_TOPK_TEST': 6000, 'POST_NMS_TOPK_TRAIN': 2000, 'POST_NMS_TOPK_TEST': 1000, 'NMS_THRESH': 0.7, 'CONV_DIMS': [-1]}), 'ROI_HEADS': CfgNode({'NAME': 'Res5ROIHeads', 'NUM_CLASSES': 80, 'IN_FEATURES': ['res4'], 'IOU_THRESHOLDS': [0.5], 'IOU_LABELS': [0, 1], 'BATCH_SIZE_PER_IMAGE': 512, 'POSITIVE_FRACTION': 0.25, 'SCORE_THRESH_TEST': 0.05, 'NMS_THRESH_TEST': 0.5, 'PROPOSAL_APPEND_GT': True}), 'ROI_BOX_HEAD': CfgNode({'NAME': '', 'BBOX_REG_LOSS_TYPE': 'smooth_l1', 'BBOX_REG_LOSS_WEIGHT': 1.0, 'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0), 'SMOOTH_L1_BETA': 0.0, 'POOLER_RESOLUTION': 14, 'POOLER_SAMPLING_RATIO': 0, 'POOLER_TYPE': 'ROIAlignV2', 'NUM_FC': 0, 'FC_DIM': 1024, 'NUM_CONV': 0, 'CONV_DIM': 256, 'NORM': '', 'CLS_AGNOSTIC_BBOX_REG': False, 'TRAIN_ON_PRED_BOXES': False, 'USE_FED_LOSS': False, 'USE_SIGMOID_CE': False, 'FED_LOSS_FREQ_WEIGHT_POWER': 0.5, 'FED_LOSS_NUM_CLASSES': 50}), 'ROI_BOX_CASCADE_HEAD': CfgNode({'BBOX_REG_WEIGHTS': ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0)), 'IOUS': (0.5, 0.6, 0.7)}), 'ROI_MASK_HEAD': CfgNode({'NAME': 'MaskRCNNConvUpsampleHead', 'POOLER_RESOLUTION': 14, 'POOLER_SAMPLING_RATIO': 0, 'NUM_CONV': 0, 'CONV_DIM': 256, 'NORM': '', 'CLS_AGNOSTIC_MASK': False, 'POOLER_TYPE': 'ROIAlignV2'}), 'ROI_KEYPOINT_HEAD': CfgNode({'NAME': 'KRCNNConvDeconvUpsampleHead', 'POOLER_RESOLUTION': 14, 'POOLER_SAMPLING_RATIO': 0, 'CONV_DIMS': (512, 512, 512, 512, 512, 512, 512, 512), 'NUM_KEYPOINTS': 17, 'MIN_KEYPOINTS_PER_IMAGE': 1, 'NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS': True, 'LOSS_WEIGHT': 1.0, 'POOLER_TYPE': 'ROIAlignV2'}), 'SEM_SEG_HEAD': CfgNode({'NAME': 'SemSegFPNHead', 'IN_FEATURES': ['p2', 'p3', 'p4', 'p5'], 'IGNORE_VALUE': 255, 'NUM_CLASSES': 54, 'CONVS_DIM': 128, 'COMMON_STRIDE': 4, 'NORM': 'GN', 'LOSS_WEIGHT': 1.0}), 'PANOPTIC_FPN': CfgNode({'INSTANCE_LOSS_WEIGHT': 1.0, 'COMBINE': CfgNode({'ENABLED': True, 'OVERLAP_THRESH': 0.5, 'STUFF_AREA_LIMIT': 4096, 'INSTANCES_CONFIDENCE_THRESH': 0.5})}), 'RETINANET': CfgNode({'NUM_CLASSES': 80, 'IN_FEATURES': ['p3', 'p4', 'p5', 'p6', 'p7'], 'NUM_CONVS': 4, 'IOU_THRESHOLDS': [0.4, 0.5], 'IOU_LABELS': [0, -1, 1], 'PRIOR_PROB': 0.01, 'SCORE_THRESH_TEST': 0.05, 'TOPK_CANDIDATES_TEST': 1000, 'NMS_THRESH_TEST': 0.5, 'BBOX_REG_WEIGHTS': (1.0, 1.0, 1.0, 1.0), 'FOCAL_LOSS_GAMMA': 2.0, 'FOCAL_LOSS_ALPHA': 0.25, 'SMOOTH_L1_LOSS_BETA': 0.1, 'BBOX_REG_LOSS_TYPE': 'smooth_l1', 'NORM': ''}), 'RESNETS': CfgNode({'DEPTH': 50, 'OUT_FEATURES': ['res4'], 'NUM_GROUPS': 1, 'NORM': 'FrozenBN', 'WIDTH_PER_GROUP': 64, 'STRIDE_IN_1X1': True, 'RES5_DILATION': 1, 'RES2_OUT_CHANNELS': 256, 'STEM_OUT_CHANNELS': 64, 'DEFORM_ON_PER_STAGE': [False, False, False, False], 'DEFORM_MODULATED': False, 'DEFORM_NUM_GROUPS': 1})}), 'INPUT': CfgNode({'MIN_SIZE_TRAIN': (800,), 'MIN_SIZE_TRAIN_SAMPLING': 'choice', 'MAX_SIZE_TRAIN': 1333, 'MIN_SIZE_TEST': 800, 'MAX_SIZE_TEST': 1333, 'RANDOM_FLIP': 'horizontal', 'CROP': CfgNode({'ENABLED': False, 'TYPE': 'relative_range', 'SIZE': [0.9, 0.9]}), 'FORMAT': 'BGR', 'MASK_FORMAT': 'polygon'}), 'DATASETS': CfgNode({'TRAIN': (), 'PROPOSAL_FILES_TRAIN': (), 'PRECOMPUTED_PROPOSAL_TOPK_TRAIN': 2000, 'TEST': (), 'PROPOSAL_FILES_TEST': (), 'PRECOMPUTED_PROPOSAL_TOPK_TEST': 1000}), 'DATALOADER': CfgNode({'NUM_WORKERS': 4, 'ASPECT_RATIO_GROUPING': True, 'SAMPLER_TRAIN': 'TrainingSampler', 'REPEAT_THRESHOLD': 0.0, 'FILTER_EMPTY_ANNOTATIONS': True}), 'SOLVER': CfgNode({'LR_SCHEDULER_NAME': 'WarmupMultiStepLR', 'MAX_ITER': 40000, 'BASE_LR': 0.001, 'BASE_LR_END': 0.0, 'MOMENTUM': 0.9, 'NESTEROV': False, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_NORM': 0.0, 'GAMMA': 0.1, 'STEPS': (30000,), 'NUM_DECAYS': 3, 'WARMUP_FACTOR': 0.001, 'WARMUP_ITERS': 1000, 'WARMUP_METHOD': 'linear', 'RESCALE_INTERVAL': False, 'CHECKPOINT_PERIOD': 5000, 'IMS_PER_BATCH': 16, 'REFERENCE_WORLD_SIZE': 0, 'BIAS_LR_FACTOR': 1.0, 'WEIGHT_DECAY_BIAS': None, 'CLIP_GRADIENTS': CfgNode({'ENABLED': False, 'CLIP_TYPE': 'value', 'CLIP_VALUE': 1.0, 'NORM_TYPE': 2.0}), 'AMP': CfgNode({'ENABLED': False})}), 'TEST': CfgNode({'EXPECTED_RESULTS': [], 'EVAL_PERIOD': 0, 'KEYPOINT_OKS_SIGMAS': [], 'DETECTIONS_PER_IMAGE': 100, 'AUG': CfgNode({'ENABLED': False, 'MIN_SIZES': (400, 500, 600, 700, 800, 900, 1000, 1100, 1200), 'MAX_SIZE': 4000, 'FLIP': True}), 'PRECISE_BN': CfgNode({'ENABLED': False, 'NUM_ITER': 200})}), 'OUTPUT_DIR': './output', 'SEED': -1, 'CUDNN_BENCHMARK': False, 'VIS_PERIOD': 0, 'GLOBAL': CfgNode({'HACK': 1.0})})"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["cfg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1710611590617,"user":{"displayName":"Mohammed El-dor","userId":"10177968864037735714"},"user_tz":-60},"id":"dhqHJ4dlZOBx","outputId":"f7d68115-5d66-4e90-9a23-d98c07daa543"},"outputs":[{"data":{"text/plain":["CfgNode({'NAME': 'build_resnet_backbone', 'FREEZE_AT': 0})"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["cfg[\"MODEL\"]['BACKBONE'] = CfgNode({'NAME': 'build_resnet_backbone', 'FREEZE_AT': 0})\n","cfg.OUTPUT_DIR = \"./Detectron2/Test_results/SGD0.99_001_00_3x101\"\n","cfg.merge_from_file(model_zoo.get_config_file(MODELS_LIST[1]))\n","cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n","cfg.DATASETS.TEST = (\"my_dataset_test\",)\n","cfg.SOLVER.MOMENTUM = 0.99 #Detectron2_cfg[\"Momentum\"]\n","cfg.SOLVER.CHECKPOINT_PERIOD = 200  # The network takes a checkpoint once it finishes of every 200 iterations\n","# cfg.TEST.EVAL_PERIOD = 20\n","cfg.DATALOADER.NUM_WORKERS = NUM_WORKERS\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(MODELS_LIST[1])  # Let training initialize from model zoo\n","cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH  # This is the real \"batch size\" commonly known to deep learning people\n","cfg.SOLVER.BASE_LR = 0.001 # Detectron2_cfg[\"base_lr\"]  # pick a good LR\n","cfg.SOLVER.MAX_ITER = 1500\n","cfg.SOLVER.STEPS = []        # do not decay learning rate\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = BATCH_SIZE_PER_IMAGE  # The \"RoIHead batch size\". 128 is faster, and good enough for this dataset (default: 512)\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES  # only has one class (Track). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n","# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n","\n","cfg.MODEL.PIXEL_MEAN = [26.9]\n","cfg.MODEL.PIXEL_STD = [34.4]\n","# for grayscale images\n","# if it gives error just remove it and make mean and std 3 values that are equal [26.9, 26.9, 26.9]\n","cfg.INPUT.FORMAT = \"L\"\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","# trainer = DefaultTrainer(cfg)\n","trainer = CustomTrainer(cfg)\n","trainer.resume_or_load(resume=True)\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N8oIOQ0qZCg2"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1cJfo4uIZ9xi3kks5AxsC9q7-E7SAfv2l","authorship_tag":"ABX9TyMOvY+QG1ufl4dlnBWhk8kV"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}